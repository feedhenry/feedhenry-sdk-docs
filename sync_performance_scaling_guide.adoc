[[sync-performance-scaling-guide]]
= Sync Server Performance & Scaling Guide

== Overview

The sync server is designed to be scalable.
In order for you to decide if scaling is required, you need to know how it performs first. 

This guide will help you to understand the performance of the sync server, and the options to scale.

== Inspecting the performance

The sync server provides 2 options for you to inspect the performance of itself:

=== 1. Query the `/mbaas/sync/stats` endpoint

By default, the sync framework will save its metrics data into Redis while it's running. 
You can then send a HTTP GET request to the `/mbaas/sync/status` endpoint to view the summary of those metrics data. 

The following information is available from this endpoint:

* CPU & Memory Usage of all the workers
* The time taken to process various jobs
* The number of the remaining jobs in various job queues
* The time taken for various API calls
* The time taken forvarious MongoDB operations

For each of those metrics, you will be able to see the total number of samples, the current, maximum, minimum and average values. 

By default, it will collect the last 1000 samples for each metric, but you can control that using the `statsRecordsToKeep` configuration option.

This endpoint is easy to use and will provide enough information for you to understand the current performance of the sync server. 
However, if you want to visualize and understand the performance over a period of time, you should consider the next option.

=== 2. Visualize the metrics data with InfluxDB and Grafana

If you want to visualize the current and historical metrics data, you can instruct the sync server to send the metrics data to InfluxDB, and see the graphs in Grafana.

There are plenty of tutorials online to help setup InfluxDB and Grafana. For example:

* http://www.netinstructions.com/installing-influxdb-and-grafana-on-an-ec2-instance/[How to setup InfluxDB and Grafana on AWS EC2]
* https://github.com/feedhenry/sync-metrics-openshift[How to setup InfluxDB and Grafana on OpenShift]

Once you have InfluxDB running, you just need to update the following configurations to instruct the sync server to send metrics data:

* metricsInfluxdbHost
* metricsInfluxdbPort

[NOTE]
====
Please make sure `metricsInfluxdbPort` is a UDP port
====

To see the metrics data graph in Grafana, you will need to create a new dashboard with graphs first. 
The quickest way is to import https://github.com/feedhenry/sync-metrics-openshift/blob/master/dashboards/sync-stats.json[this Grafana databoard file].
Once the app is running, you should start to see metrics data in the Grafana dashboard.

For more details about how to configure the Grafana graphs, please refer to the http://docs.grafana.org/[Grafana Documentation].

== Understanding the performance

To understand the performance of the sync server, here are some of the key metrics you need to look at:

=== CPU usages

This is the most important metric. 
On one hand, if CPU is over loaded, then the sync server will not be able to respond to the client requests.
On the other hand, we want to utilize the CPU usage as much as possible.

To balance that, we should establish a threshold to determine when to scale the sync server. The recommended value is 80%.

If CPU utilization is below that, the sync server doesn't need scale, and you can probably reduce a few worker interval configurations to increase the CPU usages.
However, if CPU usage is above that threshold, you should definitely consider scaling the sync server.

=== Remaining jobs in various queues

The sync server will save various jobs in queues and process them later. 

If there are many jobs left in the queues and the number keeps growing, and the CPU utilization is relatively low, you should reduce worker interval configurations to process the jobs quicker.

Otherwise, if the sync server is already under heave load, you should consider scaling the sync server to allow new workers to be created to process the jobs.

=== API response time

If you observe increases in the reponse time for various sync APIs, and the CPU usage is going up, it means the sync server is under load.
At this point, you should consider scale it.

However, if the CPU usage doesn't change much, it normally means something else is causing the slow down, and you should investigate the problem.

=== MongoDB operation time

In a production environment, the time for various MongoDB operations should be relatively low and consistent.
If you start observing increases of time for those operations, it could mean the sync server is generating too many operations on the MongoDB and starts to reach the limit of MongoDB.

In this case, scaling the sync server will not really help, because the bottleneck is in MongoDB. There are a few options you can consider:

* Turn on caching by setting the `useCache` flag to true. This should reduce the number of db requests to read dataset records.
* Increase the various worker intervals and sync frequencies.
* If possible, scale MongoDB.

== Scaling the Sync Server

If you decide to scale the sync server, here are some of the options you can consider:

=== Scaling on Dynofarm

If your app is running on the RHMAP dynofarm (all the SAAS customers are), you can use https://nodejs.org/docs/latest-v4.x/api/cluster.html[Nodejs Clustering] to create more workers.

If that's not enough, it is possible to create another app and point it to the same MongoDB to scale even further. 

//TODO: Add instruction of how to do that.

=== Scaling on OpenShift

The best way to scale the application on OpenShift is to use the auto scaling feature.

In order to do that, you first have to make sure metrics is enabled in the OpenShift cluster, and then use the `oc autoscale` command to configure when the application should be scaled.

For example, on OpenShift 3.2, here is the document of how to https://docs.openshift.com/enterprise/3.2/install_config/cluster_metrics.html#metrics-deployer[enable cluster metrics].
Then here is how to https://docs.openshift.com/enterprise/3.2/dev_guide/pod_autoscaling.html#dev-guide-pod-autoscaling[scale the application].