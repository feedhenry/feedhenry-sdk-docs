[[sync-performance-scaling-guide]]
= Sync Server Performance & Scaling Guide

== Overview

The sync server is designed to be scalable.
In order for you to decide if scaling is required, you need to know how it performs first. 

This guide will help you to understand the performance of the sync server, and the options to scale.

== Inspecting the performance

The sync server provides 2 options for you to inspect the performance of itself:

=== 1. Query the `/mbaas/sync/stats` endpoint

By default, the sync framework will save its metrics data into Redis while it's running. 
You can then send a HTTP GET request to the `/mbaas/sync/stats` endpoint to view the summary of those metrics data. 

The following information is available from this endpoint:

* CPU & Memory Usage of all the workers
* The time taken to process various jobs
* The number of the remaining jobs in various job queues
* The time taken for various API calls
* The time taken forvarious MongoDB operations

For each of those metrics, you will be able to see the total number of samples, the current, maximum, minimum and average values. 

By default, it will collect the last 1000 samples for each metric, but you can control that using the `statsRecordsToKeep` configuration option.

This endpoint is easy to use and will provide enough information for you to understand the current performance of the sync server. 
However, if you want to visualize and understand the performance over a period of time, you should consider the next option.

=== 2. Visualize the metrics data with InfluxDB and Grafana

If you want to visualize the current and historical metrics data, you can instruct the sync server to send the metrics data to InfluxDB, and see the graphs in Grafana.

There are plenty of tutorials online to help setup InfluxDB and Grafana. For example:

* https://github.com/feedhenry/sync-metrics-openshift[How to setup InfluxDB and Grafana on OpenShift]

Once you have InfluxDB running, you just need to update the following configurations to instruct the sync server to send metrics data:

* metricsInfluxdbHost
* metricsInfluxdbPort

[NOTE]
====
Please make sure `metricsInfluxdbPort` is a UDP port
====

To see the metrics data graph in Grafana, you will need to create a new dashboard with graphs first. 
The quickest way is to import https://github.com/feedhenry/sync-metrics-openshift/blob/master/dashboards/sync-stats.json[this Grafana databoard file].
Once the app is running, you should start to see metrics data in the Grafana dashboard.

For more details about how to configure the Grafana graphs, please refer to the http://docs.grafana.org/[Grafana Documentation].

== Understanding the performance

To understand the performance of the sync server, here are some of the key metrics you need to look at:

=== CPU usages

This is the most important metric. 
On one hand, if CPU is over loaded, then the sync server will not be able to respond to the client requests.
On the other hand, we want to utilize the CPU usage as much as possible.

To balance that, we should establish a threshold to determine when to scale the sync server. The recommended value is 80%.

If CPU utilization is below that, the sync server doesn't need scale, and you can probably reduce a few worker interval configurations to increase the CPU usages.
However, if CPU usage is above that threshold, you should definitely consider scaling the sync server.

=== Remaining jobs in various queues

The sync server will save various jobs in queues and process them later. 

If there are many jobs left in the queues and the number keeps growing, and the CPU utilization is relatively low, you should reduce worker interval configurations to process the jobs quicker.

Otherwise, if the sync server is already under heave load, you should consider scaling the sync server to allow new workers to be created to process the jobs.

=== API response time

If you observe increases in the reponse time for various sync APIs, and the CPU usage is going up, it means the sync server is under load.
At this point, you should consider scale it.

However, if the CPU usage doesn't change much, it normally means something else is causing the slow down, and you should investigate the problem.

=== MongoDB operation time

In a production environment, the time for various MongoDB operations should be relatively low and consistent.
If you start observing increases of time for those operations, it could mean the sync server is generating too many operations on the MongoDB and starts to reach the limit of MongoDB.

In this case, scaling the sync server will not really help, because the bottleneck is in MongoDB. There are a few options you can consider:

* Turn on caching by setting the `useCache` flag to true. This should reduce the number of db requests to read dataset records.
* Increase the various worker intervals and sync frequencies.
* If possible, scale MongoDB.

== Scaling the Sync Server

If you decide to scale the sync server, here are some of the options you can consider:

=== Scaling on Dynofarm (SAAS)

There are 2 options to scale the sync server on the RHAMP SAAS platform:

==== Use the Node.js Cluster Module

To scale inside a single app, you can use https://nodejs.org/docs/latest-v4.x/api/cluster.html[Nodejs Clustering] to create more workers.

==== Deploy More Apps

Another option is to deploy more apps but point them to the same MongoDB as the existing app. 
This will allow you to scale the sync server even further.

To do this, you should:

* Deploy a few more apps with the same code as the existing app
* Find out the MongoDB connection string of the existing app
+
It should be listed on the *Environment Varaible* screen in the App Studio, looking for a System Environment Variable called _FH_MONGODB_CONN_URL_
* Copy the value, and create a new environment variable called _SYNC_MONGODB_URL_ in the newly created apps, and paste the MongoDB url as the value.
* Redeploy the apps.

With this approch, you can separate the HTTP request handling and sync data processing completely.

For example, if there are 2 apps setup like this, App 1 and App 2, and App 1 is the cloud app that will accept HTTP requests. 
You can then:

* Set the worker concurrencies to 0 to disable all the sync workers in App 1. It will be dedicated to handle HTTP requests
* Increase the concurrencies of sync workers in App 2, and reduce the sync interval values. It will make sure the sync data is processed as quickly as possible.

Please check link:./sync_cloud_api/setConfig.adoc[$fh.sync.setConfig] for more inforamtion about how to configure the worker concurrencies.

=== Scaling on OpenShift

The best way to scale the application on OpenShift is to use the auto scaling feature.

In order to do that, you first have to make sure metrics is enabled in the OpenShift cluster, and then use the `oc autoscale` command to configure when the application should be scaled.

For example, on OpenShift 3.2, here is the document of how to https://docs.openshift.com/enterprise/3.2/install_config/cluster_metrics.html#metrics-deployer[enable cluster metrics].
Then here is how to https://docs.openshift.com/enterprise/3.2/dev_guide/pod_autoscaling.html#dev-guide-pod-autoscaling[scale the application].